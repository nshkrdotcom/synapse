### Core Philosophy

The goal is to create a robust, Elixir-native agent framework that leverages Jido's OTP-based strengths for orchestration, state management, and fault tolerance. The integration of AI/LLM capabilities (traditionally stronger in Python) will be treated as a decoupled, external service rather than a tightly managed sub-process. This simplifies the architecture and maintains a clear separation of concerns.

**Key Principles:**

1.  **Jido-Native:** The framework is built entirely on Jido's core concepts: Agents, Actions, and Skills. Developers work primarily in Elixir.
2.  **Composable Capabilities:** Agent tools are simply `Jido.Action` modules. This makes them reusable, testable, and easy to compose into complex workflows.
3.  **Decoupled AI Service:** The LLM engine (e.g., using `pydantic-ai`) runs as a separate, standalone Python service. This eliminates the need for complex Elixir-side Python environment management and process porting, making the system cleaner and more scalable.
4.  **Orchestration over Implementation:** Elixir's role is to orchestrate tasks, manage state, and execute business logic (as Jido Actions). Python's role is confined to what it does best: interfacing with LLMs to reason and decide which tools to call.

---

### Proposed MVP Architecture

The MVP consists of two main parts: the Elixir-based **Jido Core** where agents and tools are defined, and a simple, standalone **AI Service** in Python. A special `AI.Skill` acts as the bridge between them.

#### 1. The Jido Core (Elixir)

This is where all business logic, state management, and orchestration happens.

*   **Agents (`use Jido.Agent`)**: Long-running, stateful processes that manage a task. They are the "brains" of the operation, holding the state (e.g., conversation history) and deciding the overall flow.
*   **Actions (`use Jido.Action`)**: The fundamental building blocks of your system. Each action is a self-contained, stateless, and reusable unit of work with a clearly defined schema. These are the "tools" the agent can use. For example:
    *   `MyApp.Actions.GetUserDatabase`
    *   `MyApp.Actions.SendEmail`
    *   `MyApp.Actions.CalculateOrderTotal`
*   **The AI Bridge (`AI.Skill`)**: A reusable `Jido.Skill` that gives any agent the ability to think and use tools. This skill would be the core of the MVP's "agentic" capabilities and would contain two key actions:

    *   **`AI.PromptAction`**:
        *   **Purpose**: To communicate with the external Python AI Service.
        *   **Function**: Takes a prompt, message history, and a list of available `Jido.Action` modules. It serializes the actions into a JSON Schema format that LLMs understand for tool-calling and sends the request to the AI service.
        *   **Returns**: Either a final text response from the LLM or a "tool call" request.

    *   **`AI.ToolDispatcherAction`**:
        *   **Purpose**: To execute a tool requested by the LLM.
        *   **Function**: Takes a tool call request from the `PromptAction`. It finds the corresponding `Jido.Action` module in the Elixir runtime and executes it using `Jido.Workflow.run/2`.
        *   **Returns**: The result of the executed Jido Action.

#### 2. The AI Service (Python)

This is a simple, standalone web server (e.g., using FastAPI) with a single primary purpose: to serve LLM responses.

*   **Single Endpoint (`/prompt`)**:
    *   **Accepts**: A JSON payload containing `{ "messages": [...], "tools": [...] }`.
    *   **Logic**: Uses a library like `pydantic-ai` to interact with an LLM (e.g., OpenAI, Anthropic, Gemini). It passes the message history and the JSON schema for the available tools.
    *   **Returns**: A JSON response containing either the LLM's final text answer or a structured tool call request.
*   **Deployment**: This service is managed independently. It can be run in a separate terminal, a Docker container, or deployed as a serverless function. This completely decouples it from the Elixir runtime.

---

### Example Workflow: A Simple "ReAct" Agent

Here is how the components would interact in a classic Reason-Act loop to answer a question like "What is the order status for user john@example.com?".

1.  A `Jido.Agent` receives an initial instruction to find the order status. The agent's state contains the message history.

2.  The agent executes the **`AI.PromptAction`**. This action sends the current message history and the list of available tools (e.g., `MyApp.Actions.GetUser`, `MyApp.Actions.GetOrderStatus`) to the Python **AI Service**.

3.  The **AI Service** receives the request. The LLM determines it first needs to find the user's ID. It returns a JSON response requesting a tool call: `{ "tool_to_call": "MyApp.Actions.GetUser", "parameters": { "email": "john@example.com" } }`.

4.  The `AI.PromptAction` completes, returning the tool call data. The agent's workflow proceeds to the **`AI.ToolDispatcherAction`**.

5.  The **`AI.ToolDispatcherAction`** takes the tool call data, dynamically finds the `MyApp.Actions.GetUser` module in Elixir, and executes it with the provided parameters. The action runs and returns the user's data (e.g., `%{id: "user_123", name: "John Doe"}`).

6.  The agent adds both the tool call request and the tool's result to its message history.

7.  The loop repeats. The agent calls the **`AI.PromptAction`** again with the updated history. This time, the LLM has the user's ID and can call the `MyApp.Actions.GetOrderStatus` tool to get the final answer.

8.  Once the final answer is retrieved, the `AI.PromptAction` returns the text response, and the agent completes its task.

### Benefits of this MVP Approach

*   **Simplicity & Cleanliness**: Eliminates the complex, brittle process management and environment setup (`PythonEnvManager`, Ports) from the Elixir side. The interaction is a standard, stateless API call.
*   **Leverages Jido's Strengths**: Fully utilizes Jido's robust OTP patterns for agent supervision, state management, and defining capabilities as composable `Actions`.
*   **Separation of Concerns**: Elixir focuses on high-level orchestration and business logic (tools), while Python focuses on the single task of LLM interaction.
*   **Scalability & Maintainability**: The Elixir and Python components can be scaled, updated, and maintained independently. You can even have multiple specialized AI services.
*   **Extensibility**: Adding a new tool for the agent to use is as simple as defining a new `Jido.Action` and making it available to the agent. No Python code needs to change.

### Proposed MVP File Structure

```
jido_agent_framework/
├── lib/
│   ├── my_app/
│   │   ├── actions/
│   │   │   ├── get_user.ex
│   │   │   └── get_order_status.ex
│   │   ├── agents/
│   │   │   └── order_status_agent.ex
│   │   └── skills/
│   │       └── ai_skill.ex  # Contains PromptAction and ToolDispatcherAction
│   └── my_app.ex
├── mix.exs
└── ...
ai_service/
├── app/
│   ├── main.py  # FastAPI server
│   └── agent.py # pydantic-ai logic
├── Dockerfile
└── requirements.txt
```
