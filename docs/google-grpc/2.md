Okay, I understand. We'll focus on implementing the three `pydantic-ai` agent execution methods (`run_sync`, `run`, and `run_stream`) as the core of our integration, and we'll design the Elixir and Python components to support these cleanly. We'll also use four separate Python scripts as you requested.

Here's a revised design, incorporating the core principles from our previous discussion and addressing the specific requirements you've outlined:

**1. Python Side (Four Scripts):**

*   **`agent_entry.py` (Entry Script):**
    *   Responsible for starting the FastAPI application (`agent_wrapper.py`).
    *   Handles command-line arguments or environment variables for configuration (e.g., port, agent type).
    *   Activates the virtual environment.
    *   Starts the `uvicorn` server.
    *   Example command-line usage:
        ```bash
        python agent_entry.py --agent-type run_sync --port 8000
        python agent_entry.py --agent-type run --port 8001
        python agent_entry.py --agent-type run_stream --port 8002
        ```

*   **`agent_wrapper.py` (FastAPI Application):**
    *   Defines FastAPI endpoints for:
        *   `/run_sync`: Handles synchronous agent execution using the appropriate agent module.
        *   `/run`: Handles asynchronous agent execution (if needed).
        *   `/run_stream`: Handles streaming agent execution.
        *   `/tool_call`: Handles tool calls from agents.
    *   Uses a dictionary (`agent_runners`) to map agent types (from command-line arguments) to the corresponding agent runner modules (see below).
    *   Handles JSON serialization/deserialization.
    *   Implements basic error handling and logging.

*   **`run_sync_agent.py` (Synchronous Agent Runner):**
    *   Contains the logic for running a `pydantic-ai` agent synchronously using `agent.run_sync()`.
    *   Imports and uses the `pydantic-ai` `Agent` class.
    *   Defines a function `run_sync_agent(agent_config, request_data)` that:
        1. Creates a `pydantic-ai` `Agent` instance based on `agent_config`.
        2. Calls `agent.run_sync()` with the provided `request_data`.
        3. Returns the `RunResult` (or raises an exception if an error occurs).

*   **`run_agent.py` (Asynchronous Agent Runner):**
    *   Contains the logic for running a `pydantic-ai` agent asynchronously using `agent.run()`.
    *   Similar structure to `run_sync_agent.py` but uses `await agent.run()`.

*   **`run_stream_agent.py` (Streaming Agent Runner):**
    *   Contains the logic for running a `pydantic-ai` agent with streaming using `agent.run_stream()`.
    *   Implements an `async def run_stream_agent(agent_config, request_data)` function that:
        1. Creates a `pydantic-ai` `Agent` instance.
        2. Calls `agent.run_stream()` and iterates through the streamed response.
        3. Yields each chunk of the response to the caller (which will be `agent_wrapper.py`).

**2. Elixir Side (`AxonCore.AgentProcess`):**

*   **Agent Definition:** We'll continue to use a struct like `AxonCore.Agent` to define agents in Elixir, including the agent type (`run_sync`, `run`, or `run_stream`).
*   **Process Management:** The `AgentProcess` will start the appropriate Python agent runner (`run_sync_agent.py`, `run_agent.py`, or `run_stream_agent.py`) based on the agent's type using `Port.open`.
*   **Communication:** `AgentProcess` will communicate with the Python `agent_wrapper.py` via HTTP requests.
*   **Request Handling:**  `AgentProcess` will have `handle_call` clauses to handle different request types:
    *   `:run_sync`: Sends a synchronous request to `/run_sync`.
    *   `:run`: Sends an asynchronous request to `/run` (if we decide to implement this).
    *   `:run_stream`: Initiates a streaming request to `/run_stream` and sets up a WebSocket or polling mechanism.
    *   `:call_tool`: Sends a request to `/tool_call` to execute a tool.
*   **Response Handling:** `handle_info` clauses will handle responses from the Python agents, including results, errors, and streamed chunks.
*   **Streaming (WebSockets):**  We'll use WebSockets for streaming. `AgentProcess` will establish a WebSocket connection when a `run_stream` request is received and handle incoming messages.

**3. Data Structures and Schema:**

*   **Elixir:** We'll continue to use Elixir structs (like `AxonCore.Agent` and `AxonCore.Tool`) to represent agent configurations and tool definitions.
*   **JSON Schema:** We'll use JSON Schema for:
    *   Defining tool parameters.
    *   Defining the `result_type` of agents.
    *   Validating data exchanged between Elixir and Python.
*   **Schema Translation:** The `AxonCore.SchemaUtils` module will handle the translation between Elixir data structures and JSON Schema.

**File Tree (Revised):**

```
axon/
├── apps/
│   ├── axon/                 # Phoenix web application
│   │   ├── lib/
│   │   │   └── ...
│   │   └── ...
│   ├── axon_core/            # Core Elixir application
│   │   ├── lib/
│   │   │   ├── axon_core/
│   │   │   │   ├── agent.ex              # Agent definition struct
│   │   │   │   ├── agent_process.ex      # GenServer for agent management
│   │   │   │   ├── http_client.ex        # HTTP client (Finch)
│   │   │   │   ├── json_codec.ex         # JSON encoder/decoder (Jason)
│   │   │   │   ├── schema_utils.ex       # Schema translation and validation
│   │   │   │   ├── tool.ex                # Tool definition struct
│   │   │   │   └── tool_utils.ex         # Tool handling logic
│   │   │   └── ...
│   │   └── test/
│   │       └── ...
│   └── axon_python/        # Python integration
│       ├── pyproject.toml
│       ├── poetry.lock
│       ├── src/
│       │   └── axon_python/
│       │       ├── __init__.py
│       │       ├── agent_wrapper.py   # FastAPI application
│       │       ├── agent_entry.py    # Entry script to start agents
│       │       ├── run_sync_agent.py  # Synchronous agent runner
│       │       ├── run_agent.py       # Asynchronous agent runner (optional)
│       │       ├── run_stream_agent.py# Streaming agent runner
│       │       ├── agents/         # pydantic-ai agent definitions
│       │       │   ├── __init__.py
│       │       │   ├── example_agent.py
│       │       │   └── ...
│       │       ├── llm_wrapper.py     # Simplified LLM API interface
│       │       └── schemas/        # JSON schemas for data validation (if needed)
│       │           └── ...
│       └── test/
│           └── ...
├── config/
│   ├── config.exs
│   └── ...
├── lib/
│   └── axon.ex             # Main Axon application entry point
├── test/
│   └── ...
├── .gitignore
├── mix.exs                 # Umbrella project definition
├── README.md
├── start.sh
└── setup.sh
```

**Code Examples (Illustrative):**

**`agent_entry.py`:**

```python
# agent_entry.py
import argparse
import subprocess

def start_agent(agent_type: str, port: int):
    """Starts the appropriate agent runner based on agent_type."""
    if agent_type == "run_sync":
        script = "run_sync_agent.py"
    elif agent_type == "run":
        script = "run_agent.py"
    elif agent_type == "run_stream":
        script = "run_stream_agent.py"
    else:
        raise ValueError(f"Invalid agent type: {agent_type}")

    # Activate the virtual environment (consider using a better method if needed)
    activate_script = "../../.venv/bin/activate"  # Adjust path if necessary
    command = f"source {activate_script} && uvicorn {script}:app --host 0.0.0.0 --port {port}"
    # Use subprocess.Popen to run in the background if needed
    subprocess.run(command, shell=True, check=True)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Start an Axon agent.")
    parser.add_argument("--agent-type", required=True, choices=["run_sync", "run", "run_stream"],
                        help="The type of agent to start (run_sync, run, or run_stream).")
    parser.add_argument("--port", type=int, required=True, help="The port to run the agent on.")
    args = parser.parse_args()

    start_agent(args.agent_type, args.port)
```

**`agent_wrapper.py`:**

```python
# agent_wrapper.py
from typing import Callable, Dict, Any
from fastapi import FastAPI, HTTPException, Depends, WebSocket
import json
from pydantic import BaseModel, ValidationError

# Import agent runner modules
from . import run_sync_agent, run_agent, run_stream_agent

app = FastAPI()

# Map agent types to agent runner functions
agent_runners: Dict[str, Callable] = {
    "run_sync": run_sync_agent.run_sync_agent,
    "run": run_agent.run_agent,
    "run_stream": run_stream_agent.run_stream_agent,
}

# ... other helper functions ...

# Error model
class ErrorResponse(BaseModel):
    status: str = "error"
    error_type: str
    message: str
    details: Optional[Any] = None

# Dependency to get agent configuration based on agent_id
async def get_agent_config(agent_id: str) -> dict:
    config = agent_configs.get(agent_id)
    if not config:
        raise HTTPException(status_code=404, detail="Agent not found")
    return config

@app.post("/agents/{agent_id}/run_sync", response_model=RunResult)
async def run_sync_endpoint(agent_id: str, request_data: dict, agent_config: dict = Depends(get_agent_config)):
    try:
        agent_runner = agent_runners["run_sync"]
        result = agent_runner(agent_config, request_data)
        return result
    except ValidationError as e:
        return JSONResponse(
            status_code=400,
            content=ErrorResponse(error_type="ValidationError", message=str(e), details=e.errors()).model_dump_json()
        )
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content=ErrorResponse(error_type=type(e).__name__, message=str(e)).model_dump_json()
        )

@app.websocket("/agents/{agent_id}/run_stream")
async def run_stream_endpoint(websocket: WebSocket, agent_id: str, agent_config: dict = Depends(get_agent_config)):
    await websocket.accept()
    try:
        agent_runner = agent_runners["run_stream"]
        async for chunk in agent_runner(agent_config, {}):  # Pass empty dict for initial request data
            await websocket.send_text(json.dumps(chunk))
        await websocket.close()
    except Exception as e:
        await websocket.send_json(
            ErrorResponse(error_type=type(e).__name__, message=str(e)).model_dump_json()
        )
        await websocket.close()

# ... other endpoints for /run, /tool_call, /log ...
```

**`run_sync_agent.py`:**

```python
# run_sync_agent.py
from pydantic_ai import Agent
from pydantic import BaseModel

def run_sync_agent(agent_config: dict, request_data: dict) -> dict:
    """Runs a pydantic-ai agent synchronously."""

    # 1. Create Agent instance based on agent_config
    #    - You might need to dynamically import the agent class based on
    #      agent_config["agent_class"] or similar.
    #    - Resolve tools, result_type, etc. from agent_config.

    # Example:
    class ResultType(BaseModel):
        result: str

    agent = Agent(
        model=agent_config["model"],
        system_prompt=agent_config["system_prompt"],
        result_type=ResultType,
        # ... other agent parameters ...
    )

    # 2. Call agent.run_sync()
    result = agent.run_sync(request_data["prompt"], message_history=request_data.get("message_history", []))

    # 3. Return the result (or raise an exception)
    return {
        "result": result.data.model_dump_json(),  # Convert Pydantic model to JSON string
        "usage": result.usage.model_dump_json() if result.usage else None  # Convert Usage to JSON string if available
    }
```

**`run_stream_agent.py`:**

```python
# run_stream_agent.py
from pydantic_ai import Agent
from pydantic import BaseModel
import asyncio  # Import the asyncio module

async def run_stream_agent(agent_config: dict, request_data: dict) -> AsyncIterator[dict]:
    """Runs a pydantic-ai agent with streaming."""

    # 1. Create Agent instance (similar to run_sync_agent.py)
    # ...
     # Example:
    class ResultType(BaseModel):
        result: str
    
    agent = Agent(
        model=agent_config["model"],
        system_prompt=agent_config["system_prompt"],
        result_type=ResultType
        # ... other agent parameters ...
    )

    # 2. Call agent.run_stream()
    async with agent.run_stream(request_data["prompt"], message_history=request_data.get("message_history", [])) as stream:
        # 3. Yield each streamed chunk
        async for text in stream.stream_text():  # Assuming you want to stream the text part
            yield {"status": "chunk", "data": text}
        
        # 4. Yield the final result when the stream is finished
        yield {"status": "complete", "result": stream.result.data.model_dump_json(), "usage": stream.result.usage.model_dump_json() if stream.result.usage else None}
```

**`AxonCore.AgentProcess` (Elixir):**

```elixir
# ...

def handle_call({:run_sync, agent_id, request}, from, state) do
  # 1. Construct the request payload (JSON).
  # 2. Send an HTTP POST request to /agents/{agent_id}/run_sync.
  # 3. Handle the response (success or error).
  # 4. Reply to the caller.
end

def handle_call({:run_stream, agent_id, request}, from, state) do
  # 1. Establish a WebSocket connection to /agents/{agent_id}/run_stream.
  # 2. Send an initial message if needed.
  # 3. Handle incoming messages (chunks, completion, errors).
  # 4. Forward chunks to the original caller using `send(from, {:chunk, chunk})`.
  # 5. Reply to the caller when the stream is complete or an error occurs.
end

# ... other handlers for tool calling, etc. ...
```

This comprehensive outline should give you a solid foundation for implementing the different agent execution modes. Remember to focus on building a minimal, functional version first and then gradually add more features and error handling.
